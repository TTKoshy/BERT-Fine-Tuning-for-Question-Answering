# BERT-Fine-Tuning-for-Question-Answering

Overview

This project fine-tunes a BERT (Bidirectional Encoder Representations from Transformers) model for Question Answering (QA) tasks. The notebook leverages a pre-trained BERT model and adapts it to extract answers from given text passages based on a provided question.

Features

- Loads a pre-trained BERT model from Hugging Face.

- Prepares and tokenizes a dataset for QA.

- Fine-tunes BERT using SQuAD dataset.

- Evaluates the model's performance.

- Demonstrates predictions on sample inputs.
